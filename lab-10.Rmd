ins---
title: "Lab 10 - Grading the professor, Pt. 1"
author: "Insert your name here"
date: "Insert date here"
output: github_document
---

## Load Packages and Data

```{r load-packages, message=FALSE, warning=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
library(broom)
library(viridis)
library(ggplot2)

```

## Exercise 1

*Provide your answer here.*  
Add code chunks as needed. Don't forget to label your code chunks.


```{r exercise1_code}
# Add your R code here

data("evals")
view(evals)

evals$prof_id <- as.factor(evals$prof_id)

```

```{r plot}
ggplot(evals, aes(x = reorder(course_id, score), y = score)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Bar Chart of Score by Course (Ordered by Score)",
    x = "Evaluations Ordered From Lowest to Highest",
    y = "Attractiveness Score")+
  theme_classic() +
  theme(axis.text.x = element_blank(),   # Remove x-axis labels
    axis.ticks.x = element_blank())
  
```

Yes the distribution appears to be skewed such that there is a positive skew. Most professors recieved a positive score (above 3).

This mostly fits what I would expect. Most professors get pretty good scores but their ratings seem to drop more sharply below a rating of 3--likely because if they are notably bad, students are more likely to agree that they are that bad.

## Exercise 2

"Create a scatterplot of score versus bty_avg (a professor’s average beauty rating). Describe any pattern you observe—does there appear to be a trend, clustering, or wide variation? Don’t overthink it; just describe what you see."

```{r scatterplot}
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_point() +
  labs(
    title = "Scatterplot of Score vs. Beauty Average",
    x = "Beauty Average",
    y = "Score") +
  theme_classic()
```
It seems that beauty does correlate with evaluation scores, especially when you look at the lower scores. It seems that if a professor is more attractive, they are less likely to recieve a lower score. Beauty does not seem to effect higher scores (ceiling effect?).

##Exercise 3

```{r jitter}
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  labs(
    title = "Scatterplot of Score vs. Beauty Average",
    x = "Beauty Average",
    y = "Score") +
  theme_classic()
```
This reveals all the clusters that were obscured in the previous graph because the points were stacked on one another. I don't think this changes too much about the interpretation however, it visually emphasized the correlation I described earlier.

##Exercise 4
"Let’s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called m_bty to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model."

```{r regression}
m_bty <- lm(score ~ bty_avg, data = evals)
summary(m_bty)
```
The linear model is: score = 3.88 + 0.067*x

##Exercise 5
"Replot your visualization from Exercise 3, this time add a regression line in orange. Turn off the default shading around the line. By default, the plot includes shading around the line—what does that shading represent? And speculate why I’m asking you to turn it off."

The line represents the 95% CI around the regression line. Turning it off simplifies the graph and makes it easier to read.

```{r ex5}
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_jitter() +
  labs(
    title = "Scatterplot of Score vs. Beauty Average",
    x = "Beauty Average",
    y = "Score") +
  geom_smooth(method = "lm",
             color = "orange",
             se = FALSE)+
  theme_classic()
```


## Exercise 6
The slope of this model indicates that professor evaluations are more positive as beauty average increase.

##Exercise 7
The intercept represents the theoretical evaluation score of a professor with a beauty rating of 0. This is more of a mathematical artifact than actually meaningful because no professor got a score lower than 1.67.

##Exercise 8
R^2 is .033 which means that beauty explains 3.3% of the variance in professor evaluations.


##Exercise 9
```{r ex9_lm}
m_gen <- lm(score ~ gender, data = evals)
tidy(m_gen)

summary(m_gen)
```

The reference level is female. This means that we can interpret the estimate as the effect on scores as a result of being male compared to female. Being male has a .14 increase.

##Exercise 10
the equation is score = 4.09 + .14*x and for males this is score = 4.23 and for females score = 4.09.

##Exercise 11

```{r rank}
m_rank <- lm(score ~ rank, data = evals)
tidy(m_rank)
```

score = 4.28 + -.13(tenure track) + -.15(tenured)
when accounting for the rank of professor, being on tenure track decreases the score by .13 and being tenured decreases the score by .15. This means that the average score of a tenure track professor is 4.15 and the average score of a tenured professor is 4.13. If they are simply teaching, that is represetned by the intercept so their score would be 4.28--on average.

##Exercise 12
"Create a new variable called rank_relevel where "tenure track" is the baseline level."

```{r relevel}

 evals <- evals %>%
  mutate(rank_relevel = relevel(rank, ref = "tenure track"))

m_rank_releveled<- lm(score ~ rank_relevel, data = evals)
tidy(m_rank_releveled)

summary(m_rank_releveled)

```

##Exercise 13

The linear model is score = 4.116 + .13(teaching) + -.016(tenured)

This means that teaching increases professors scores by .13 and being tenured decreases their scores by .016 while tenure track is the reference and the average is 4.12.

multiple r^2 = .012 adjusted = .0073
this means taht this model accountsfor 1.2% of the varience in evaluation scores.

##Exercise 14
"Create another new variable called tenure_eligible that labels "teaching" faculty as "no" and labels "tenure track" and "tenured" faculty as "yes"."

```{r mutate}
evals <- evals %>%
  mutate(tenure_eligible = ifelse(rank == "teaching", "no", "yes"))

```


##Exercise 15
"Fit a new linear model called m_tenure_eligible to predict average professor evaluation score based on tenure_eligibleness of the professor. This is the new (regrouped) variable you created in Exercise 15. Based on the regression output, write the linear model and interpret the slopes and intercept in context of the data. Also determine and interpret the  
R2 of the model."

```{r lm_tenure_eligible}
m_tenure_eligible <- lm(score ~ tenure_eligible, data = evals)

summary(m_tenure_eligible)
```
The linear model is score = 4.28 + -.14(eligible for tenure)

the intercept means that for professors that are not eligible for tenure, their average scores are 4.28. If professors are eligible, there is a, on average, .14 decrease in score.

R2 is .012 which means that this explains 1.2% of the variance in evaluation scores.
